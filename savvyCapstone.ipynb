{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dependencies\n",
    "\n",
    "import requests\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Only make API calls that were needed based on list of cities from happiness score data\n",
    "\n",
    "\n",
    "#Create a list of cities to use to make API call\n",
    "#import happiness data csv\n",
    "\n",
    "import_happiness_states = pd.read_csv(\"Happiness.csv\", encoding='ansi')\n",
    "\n",
    "#need pandas .copy function to create an unchanging version of the original\n",
    "df_cities = import_happiness_states.copy()\n",
    "\n",
    "#df.drop(['Overall Rank', 'Total Score', 'Emotional & Physical Well-Being','Income & Employment', 'Community & Environment'], axis=1)\n",
    "df_cities.drop(df_cities.columns[[0, 2, 3,4,5]], axis=1, inplace=True)\n",
    "\n",
    "hplist = df_cities['City'].tolist()\n",
    "print(hplist)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare list of Happiness Cities for loop by dropping the comma and state\n",
    "\n",
    "updated_hplist = []\n",
    "for x in range(len(hplist)):\n",
    "    \n",
    "   \n",
    "    updated_hplist.append(hplist[x][:-4])\n",
    "\n",
    "#test output\n",
    "# print(updated_hplist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#API call to get a list of cities\n",
    "\n",
    "\n",
    "url = \"https://zylalabs.com/api/226/cities+cost+of+living+and+average+prices+api/232/get+cities\"\n",
    "    \n",
    "headers = {\n",
    "    'Authorization': 'Bearer 326|qySQCd3uZ7I39Bh8v1680nDrxjlB0liuk1zvdCXv'\n",
    "}\n",
    "\n",
    "#data is the list of cities\n",
    "    \n",
    "data = requests.request(\"GET\", url, headers=headers).json()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cost of living Cities\n",
    "\n",
    "#compare the list of Happiness cites to cost of living cities\n",
    "#if CoL city (from API call) is inside of Happiness cities (updated_hplist) append to matching cities\n",
    "#then do length of matching cities list to see how many matches\n",
    "\n",
    "matching_cities = []\n",
    "\n",
    "for x in range(len(data['cities'])):\n",
    "    \n",
    "  if data['cities'][x]['country_name'] == \"United States\":\n",
    "            \n",
    "    current_city = (data['cities'][x]['city_name'] + \", \" + data['cities'][x]['state_code'])\n",
    "\n",
    "    if current_city in updated_hplist:\n",
    "      \n",
    "      matching_cities.append(current_city)\n",
    "      \n",
    "#Check number of cities to make sure there are enough matches\n",
    "print(len(matching_cities))\n",
    "\n",
    "#Test response\n",
    "# if (response_data['cities'][0]['city_name']) == \"Herat\":\n",
    "#     print(\"Herat is in the list\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compare matching cities in the API with cities from the happiness database and make a list of missing cities\n",
    "\n",
    "missing_cities = []\n",
    "\n",
    "for x in hplist:\n",
    "    if x not in matching_cities:\n",
    "           missing_cities.append(x)\n",
    "\n",
    "print(missing_cities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Test response from API\n",
    "# if (response_data['cities'][0]['city_name']) == \"Herat\":\n",
    "#     print(\"Herat is in the list\")\n",
    "\n",
    "#Test happiness Data response\n",
    "# df_cities['State'] = df_cities['City'].str[-2:]\n",
    "# df_cities['City'] = df_cities['City'].str[:-4]\n",
    "\n",
    "# df_cities['State']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use API call to get city data and store in a json\n",
    "\n",
    "#create empty lists to fill with appended data\n",
    "api_city = []\n",
    "api_state = []\n",
    "cities = []\n",
    "#more here\n",
    "\n",
    "#change index values to loop through entire column of cities when ready\n",
    "for city in df_cities['City']:\n",
    "    #print(city)\n",
    "    try:\n",
    "    \n",
    "        city_no_spaces = city.replace(\" \", \"+\")\n",
    "        url = \"https://zylalabs.com/api/226/cities+cost+of+living+and+average+prices+api/233/get+prices?city_id=2294&city_name=\"+city_no_spaces+\"&country_name=united+states\"\n",
    "        #print(url)\n",
    "        headers = {'Authorization': 'Bearer 476|T9c5gji6ogKFXaEZxz8ChZTpaON6VJ2ejSzGG8aQ'}\n",
    "                    \n",
    "        response = requests.request(\"GET\", url, headers=headers).json()\n",
    "        r = response\n",
    "        # api_city.append(response['city_name'])\n",
    "        # api_state.append(response['state_code'])\n",
    "        cities.append(r)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "        continue\n",
    "    #pull the cost data here and append to empty lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save API data locally\n",
    "\n",
    "df_fullcoldata = pd.DataFrame(cities)\n",
    "\n",
    "df_fullcoldata.to_csv('fullcoldata.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cities[0]['state_code'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create column names as feature list for the final dataframe\n",
    "#Started with State to ensure first column is state\n",
    "# https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.Series.tolist.html\n",
    "\n",
    "df_prices = pd.DataFrame(r['prices']) \n",
    "\n",
    "\n",
    "\n",
    "featureslist = ['State']\n",
    "\n",
    "for x in df_prices['item_name']:\n",
    "    featureslist.append(x)\n",
    "#feature_list\n",
    "\n",
    "print(featureslist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Use a loop to Pull all averages value from API response json and store in a dictionary \n",
    "\n",
    "#city_averages = []\n",
    "city_avgs_dict = {}\n",
    "\n",
    "for city_object in cities:\n",
    "\n",
    "    city_avgs = []\n",
    "    \n",
    "    try:\n",
    "        city = city_object['city_name']\n",
    "        state = city_object['state_code']\n",
    "        price_object = (city_object['prices'])\n",
    "\n",
    "    except Exception as e:\n",
    "       continue\n",
    "        # print(city_object)\n",
    "        # print(e)\n",
    "    finally:\n",
    "\n",
    "#create dataframe of city and average prices of select objects\n",
    "        city_avgs.append(state)\n",
    "\n",
    "        for x in range(len(price_object)):\n",
    "            average = price_object[x]['avg']\n",
    "            city_avgs.append(average)\n",
    "\n",
    "        city_avgs_dict[city] = city_avgs\n",
    "            \n",
    "print(city_avgs_dict)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(city_avgs_dict, orient='index', columns=featureslist)\n",
    "\n",
    "\n",
    "df_coledit = df.copy()\n",
    "\n",
    "#export to csv to clean column names\n",
    "\n",
    "df_coledit.to_csv('coldata_full_.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import csv with cleaned column names\n",
    "df_col = pd.read_csv('coldata_full_.csv')\n",
    "\n",
    "#need pandas .copy function to create an unchanging version of the original\n",
    "df_coledit = df_col.copy()\n",
    "\n",
    "df_coledit.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean the data the cost of living csv\n",
    "#App is unstable and giving errors. support aware but completed fix unknown\n",
    "#converted wrong values and nulls to median\n",
    "\n",
    "median_value = df_coledit['Chicken Breasts (1 kg)'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Chicken Breasts (1 kg)'] > 15.43, 'Chicken Breasts (1 kg)' ] = median_value\n",
    "\n",
    "median_valuegb = df_coledit['Ground Beef, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Ground Beef, 1 kg'] > 12, 'Ground Beef, 1 kg' ] = median_valuegb\n",
    "\n",
    "median_valuebw = df_coledit['Bottle of Wine'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Bottle of Wine'] > 18.5, 'Bottle of Wine' ] = median_valuebw\n",
    "\n",
    "median_valueb = df_coledit['Banana, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Banana, 1 kg'] > 3.59, 'Banana, 1 kg' ] = median_valueb\n",
    "\n",
    "median_valueeg = df_coledit['Eggs, 12 pack'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Eggs, 12 pack'] > 13.22, 'Eggs, 12 pack' ] = median_valueeg\n",
    "\n",
    "median_valuelt = df_coledit['Lettuce, 1 head'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Lettuce, 1 head'] > 9.5, 'Lettuce, 1 head' ] = median_valuelt\n",
    "\n",
    "median_valuebd = df_coledit['White Bread (loaf)'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['White Bread (loaf)'] > 10, 'White Bread (loaf)' ] = median_valuebd\n",
    "\n",
    "median_valuecz = df_coledit['Local Cheese, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Local Cheese, 1 kg'] > 14.7, 'Local Cheese, 1 kg' ] = median_valuecz\n",
    "\n",
    "median_valueo = df_coledit['Onion, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Onion, 1 kg'] > 9, 'Onion, 1 kg' ] = median_valueo\n",
    "\n",
    "median_valuemk = df_coledit['Milk, 1 liter'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Milk, 1 liter'] > 8.39, 'Milk, 1 liter' ] = median_valuemk\n",
    "\n",
    "median_valueor = df_coledit['Oranges, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Oranges, 1 kg'] > 10, 'Oranges, 1 kg' ] = median_valueor\n",
    "\n",
    "\n",
    "median_valuepo = df_coledit['Potato, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Potato, 1 kg'] > 5.64, 'Potato, 1 kg' ] = median_valuepo\n",
    "\n",
    "median_valuerc = df_coledit['White Rice, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['White Rice, 1 kg'] > 11, 'White Rice, 1 kg' ] = median_valuerc\n",
    "\n",
    "median_valueto = df_coledit['Tomato, 1 kg'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Tomato, 1 kg'] > 7.34, 'Tomato, 1 kg' ] = median_valueto\n",
    "\n",
    "median_valuew = df_coledit['Water, 1.5 liter'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Water, 1.5 liter'] > 4.75, 'Water, 1.5 liter' ] = median_valuew\n",
    "\n",
    "median_valuew = df_coledit['Water, 1.5 liter'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Water, 1.5 liter'] < .57, 'Water, 1.5 liter' ] = median_valuew\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "median_value1bd = df_coledit['One bedroom apartment '].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['One bedroom apartment '] < 475, 'One bedroom apartment ' ] = median_value1bd\n",
    "\n",
    "median_value1bd = df_coledit['One bedroom apartment '].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['One bedroom apartment '] > 2695.6, 'One bedroom apartment ' ] = median_value1bd\n",
    "\n",
    "median_value3bd = df_coledit['Three bedroom apartment '].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Three bedroom apartment '] > 4524.14, 'Three bedroom apartment ' ] = median_value3bd\n",
    "\n",
    "median_value3bd = df_coledit['Three bedroom apartment '].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Three bedroom apartment '] < 850, 'Three bedroom apartment ' ] = median_value3bd\n",
    "\n",
    "median_valueut = df_coledit['Basic utilities (Electricity, Heating or Cooling, Water and Garbage)'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Basic utilities (Electricity, Heating or Cooling, Water and Garbage)'] < 103.28, 'Basic utilities (Electricity, Heating or Cooling, Water and Garbage)' ] = median_valueut\n",
    "\n",
    "df_coledit['Basic utilities (Electricity, Heating or Cooling, Water and Garbage)'].fillna(value=median_valueut, inplace=True)\n",
    "\n",
    "median_valueweb = df_coledit['Internet, 60 Mbps or More, Unlimited Data, Cable/ADSL'].median()\n",
    "\n",
    "df_coledit.loc[df_coledit['Internet, 60 Mbps or More, Unlimited Data, Cable/ADSL'] < 24, 'Internet, 60 Mbps or More, Unlimited Data, Cable/ADSL' ] = median_valueweb\n",
    "\n",
    "df_coledit['Internet, 60 Mbps or More, Unlimited Data, Cable/ADSL'].fillna(value=median_valueweb, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_coledit.to_csv('coldata_full_final.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Going forward, finding an API that is stable.  API is not stable and gives too many errors\n",
    "#Possible to web scrape the Numbeo cost of living website\n",
    "# Bureau of Labor Statistics data may work here"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "072753f373865d6b158186b1f0f724b867295c26eb910829b189e1358af2d495"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
